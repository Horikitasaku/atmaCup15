{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet + mBERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7891\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7891\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "train = pd.read_csv(\"./train/train.csv\")\n",
    "test = pd.read_csv(\"./test/test.csv\")\n",
    "anime = pd.read_csv(\"./train/anime.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理コード\n",
    "def scaling(data):\n",
    "    sc = StandardScaler()\n",
    "    data_sc = np.log1p(data)\n",
    "    data_sc = sc.fit_transform(data_sc)\n",
    "    return data_sc\n",
    "\n",
    "class AnimePreprocessTabNet(object):\n",
    "    def __init__(self, df, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        # 前処理関数一覧\n",
    "        self.preprocessing_methods = [\n",
    "            \"anime_id\",\n",
    "            \"genres\",\n",
    "            \"japanese_name\",\n",
    "            \"type\",\n",
    "            \"episodes\",\n",
    "            \"aired\",\n",
    "            \"producers\",\n",
    "            \"licensors\",\n",
    "            \"studios\",\n",
    "            \"source\",\n",
    "            \"duration\",\n",
    "            \"rating\",\n",
    "            \"members\",\n",
    "            \"watching\",\n",
    "            \"completed\",\n",
    "            \"on_hold\",\n",
    "            \"dropped\",\n",
    "            \"plan_to_watch\",\n",
    "            \"concat_string_feature\"\n",
    "        ]\n",
    "\n",
    "    def preprocess_all(self):\n",
    "        # すべての処理を実行する\n",
    "        for method_name in self.preprocessing_methods:\n",
    "            getattr(self, method_name)()\n",
    "        return self.df\n",
    "\n",
    "    def anime_id(self):...\n",
    "    \n",
    "    def genres(self):\n",
    "        \"\"\"Create 26-dim embedding\"\"\"\n",
    "        chars = ['Comedy', 'Sci-Fi', 'Seinen', 'Slice of Life', 'Space',\n",
    "        'Adventure', 'Mystery', 'Historical', 'Supernatural', 'Fantasy',\n",
    "        'Ecchi', 'School', 'Harem', 'Romance', 'Shounen', 'Action',\n",
    "        'Magic', 'Sports', 'Super Power', 'Drama', 'Thriller', 'Music',\n",
    "        'Shoujo', 'Demons', 'Mecha', 'Game', 'Josei', 'Cars',\n",
    "        'Psychological', 'Parody', 'Samurai', 'Military', 'Shoujo Ai',\n",
    "        'Kids', 'Martial Arts', 'Horror', 'Dementia', 'Vampire',\n",
    "        'Shounen Ai', 'Hentai', 'Yaoi', 'Police']\n",
    "        genres = self.df[['anime_id','genres']]\n",
    "        genres.loc[:,chars] = 0\n",
    "        genres['genres'] = genres['genres'].str.split(',')\n",
    "        # genres[chars] = 0\n",
    "        for i, row in genres.iterrows():\n",
    "            for index in (s.strip() for s in row['genres']):\n",
    "                    genres.loc[i,index] = 1\n",
    "        genres = genres.drop('genres',axis=1)\n",
    "        self.df = pd.merge(self.df, genres, on=\"anime_id\", how=\"left\")\n",
    "    \n",
    "    def japanese_name(self):...\n",
    "    \n",
    "    def type(self):\n",
    "        # 単純にラベルエンコーディング\n",
    "        encoder = LabelEncoder()\n",
    "        self.df[\"type\"] = encoder.fit_transform(self.df[\"type\"])\n",
    "    \n",
    "    def episodes(self):\n",
    "        unknown_mask = self.df[\"episodes\"] == \"Unknown\"\n",
    "        self.df.loc[~unknown_mask, \"episodes\"] = scaling(\n",
    "            self.df.loc[~unknown_mask, \"episodes\"].astype(int).to_numpy().reshape(-1, 1)\n",
    "        )\n",
    "        self.df.loc[unknown_mask, \"episodes\"] = -1\n",
    "        self.df[\"episodes\"] = self.df[\"episodes\"].astype(float)\n",
    "    def to_year(self,s):\n",
    "        match = re.search(r'\\d{4}', s)\n",
    "        if match:\n",
    "            return int(match.group())\n",
    "        else:\n",
    "            return 1000\n",
    "    def aired(self):\n",
    "        # 扱いにくそうなので、一度落とす\n",
    "        self.df['year'] = self.df['aired'].apply(self.to_year)\n",
    "        self.df = self.df.drop(columns=[\"aired\"])\n",
    "\n",
    "    def producers(self):\n",
    "        \"\"\"制作会社の総数を算出する。また、後で言語変数としても使う\n",
    "        \"\"\"\n",
    "        self.df[\"num_producers\"] = self.df[\"producers\"].str.split(\",\").str.len()\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"num_producers\"] = scaling(self.df[[\"num_producers\"]].to_numpy())\n",
    "    \n",
    "    def licensors(self):...\n",
    "    \n",
    "    def studios(self):\n",
    "        # 単純にラベルエンコーディング\n",
    "        encoder = LabelEncoder()\n",
    "        self.df[\"studios\"] = encoder.fit_transform(self.df[\"studios\"])\n",
    "    \n",
    "    def source(self):\n",
    "        # 単純にラベルエンコーディング\n",
    "        encoder = LabelEncoder()\n",
    "        self.df[\"source\"] = encoder.fit_transform(self.df[\"source\"])\n",
    "    \n",
    "    def duration(self):\n",
    "        unknown_mask = self.df[\"duration\"] == \"Unknown\"\n",
    "        self.df.loc[self.df[\"duration\"].str.contains(\"hr\"), \"duration\"] = \\\n",
    "            self.df.loc[self.df[\"duration\"].str.contains(\"hr\"), \"duration\"]\\\n",
    "                    .str.extract(\"(\\d+)\")[0].astype(float) * 60\n",
    "        self.df[\"duration\"] = self.df[\"duration\"].str.extract(\"(\\d+)\")[0]\n",
    "        self.df[\"duration\"] = self.df[\"duration\"].astype(float)\n",
    "        self.df.loc[~unknown_mask, \"duration\"] = scaling(\n",
    "            self.df.loc[~unknown_mask, \"duration\"].to_numpy().reshape(-1, 1)\n",
    "        )\n",
    "        self.df[\"duration\"] = self.df[\"duration\"].fillna(-1).astype(int)\n",
    "\n",
    "    def rating(self):...\n",
    "    \n",
    "    def members(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"members\"] = scaling(self.df[[\"members\"]].to_numpy())\n",
    "    \n",
    "    def watching(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"watching\"] = scaling(self.df[[\"watching\"]].to_numpy())\n",
    "    \n",
    "    def completed(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"completed\"] = scaling(self.df[[\"completed\"]].to_numpy())\n",
    "    \n",
    "    def on_hold(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"on_hold\"] = scaling(self.df[[\"on_hold\"]].to_numpy())\n",
    "    \n",
    "    def dropped(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"dropped\"] = scaling(self.df[[\"dropped\"]].to_numpy())\n",
    "    \n",
    "    def plan_to_watch(self):\n",
    "        # 対数変換→ 標準化\n",
    "        self.df[\"plan_to_watch\"] = scaling(self.df[[\"plan_to_watch\"]].to_numpy())\n",
    "    \n",
    "    def concat_string_feature(self):\n",
    "        # 文字列として扱う列を結合し、元の列を落とす\n",
    "        concat_feature = [\n",
    "            \"japanese_name\",\n",
    "            \"genres\",\n",
    "            \"producers\",\n",
    "            \"licensors\",\n",
    "            \"studios\",\n",
    "            \"rating\"\n",
    "        ]\n",
    "        # スペース区切りで結合する\n",
    "        self.df[concat_feature] = self.df[concat_feature].astype(str)\n",
    "        self.df['combined_features'] = self.df[concat_feature].agg(' '.join, axis=1)\n",
    "        # 元の列を落とす\n",
    "        self.df = self.df.drop(columns=concat_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airedについてもくっつけて一緒にembeddingすることができますが、このときは「なんとなく扱いにくそうだなあ(バイアスがかかりそうだなあ)」と思って一旦ドロップしちゃいました。  \n",
    "使っても全く問題ないと思います。  \n",
    "カテゴリカル変数はラベルエンコーディング、数値特徴量は基本的に対数変換→ 標準化を行い、欠損や欠損に該当しそうなUnknownという値は-1を入れています。(書いていて気づいたんですが、これだと異常値として認識させられていないですね。皆さんは気をつけましょう。。。)  \n",
    "経験的に、以下の特徴量の作り方だとTabNetの学習がうまく行きやすい気がします。  \n",
    "- カテゴリカル変数は基本ラベルエンコーディングのあとembedding\n",
    "- 数値特徴量は対数変換→ 標準化\n",
    "- 特徴量間の交互作用はTabNetが見つけてくれるので、自分で作成した交互作用を表すお気持ちの特徴量は全部落とす\n",
    "\n",
    "LightGBMの後にTabNetを試されるケースが多いのかなと思うので、特に3つ目を意識すると性能を引き出しやすいと感じていますが、残念ながらn=1なので本当のところはよくわかりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Horikita_Saku\\AppData\\Local\\Temp\\ipykernel_21652\\1650585605.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genres.loc[:,chars] = 0\n",
      "C:\\Users\\Horikita_Saku\\AppData\\Local\\Temp\\ipykernel_21652\\1650585605.py:54: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  genres.loc[:,chars] = 0\n",
      "C:\\Users\\Horikita_Saku\\AppData\\Local\\Temp\\ipykernel_21652\\1650585605.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genres['genres'] = genres['genres'].str.split(',')\n"
     ]
    }
   ],
   "source": [
    "anime_preprocess = AnimePreprocessTabNet(df=anime, mode=\"train\")\n",
    "x = anime_preprocess.preprocess_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERTによるembedding\n",
    "\n",
    "今回は日本語と英語が混ざっている特徴量を扱うので、日本語特化 or 英語特化ではなく、多言語を学習したモデルが望ましいと思いました。  \n",
    "そこでmultilingual BERTを使ってみます。  \n",
    "なお、本notebookで扱うモデルであるTabNetとは、ライブラリの依存関係が面倒なため、mBERT、その他言語モデルによる特徴量埋め込みとTabNetは仮想環境を分けることをおすすめします。  \n",
    "あと、このコードはChatGPTくんが8割くらい書いてくれました。  \n",
    "書くのめんどいな～って思って投げると爆速で書いてくれるので本当にありがたい・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self, device=None):\n",
    "        self.model = BertModel.from_pretrained('model/mBert')\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def get_embeddings(self, texts, batch_size=16):\n",
    "        dataset = TextDataset(texts)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader):\n",
    "                inputs = {name: tensor.to(self.device) for name, tensor in batch.items()}\n",
    "                outputs = self.model(**inputs)\n",
    "                embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddingを作っていきます。  \n",
    "RTX3070のミドルエンドGPUでも、このデータ規模ならすぐ終わります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodingする\n",
    "embedder = TextEmbedder()\n",
    "embeddings = embedder.get_embeddings(anime_preprocess.df['combined_features'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabNetと環境を分ける都合上、保存しておいてください。  \n",
    "本来はここでnotebookも一度分かれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量は保存しておく\n",
    "with open(\"./train/mBERT_embedding_01EDA.npy\", \"wb\") as f:\n",
    "    np.save(f, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとはこれをくっつけたらOKです。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./train/mBERT_embedding_01EDA.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime_preprocessd = anime_preprocess.df.copy()\n",
    "df_anime_preprocessd = df_anime_preprocessd.drop(columns=[\"combined_features\"])\n",
    "embeddings_columns = [f\"mBERT_{i}\" for i in range(embeddings.shape[1])]\n",
    "embeddings_df = pd.DataFrame(data=embeddings, columns=embeddings_columns)\n",
    "df_anime_preprocessd = df_anime_preprocessd.join(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>source</th>\n",
       "      <th>duration</th>\n",
       "      <th>members</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>...</th>\n",
       "      <th>mBERT_758</th>\n",
       "      <th>mBERT_759</th>\n",
       "      <th>mBERT_760</th>\n",
       "      <th>mBERT_761</th>\n",
       "      <th>mBERT_762</th>\n",
       "      <th>mBERT_763</th>\n",
       "      <th>mBERT_764</th>\n",
       "      <th>mBERT_765</th>\n",
       "      <th>mBERT_766</th>\n",
       "      <th>mBERT_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ba7f7e34e107e7544</td>\n",
       "      <td>5</td>\n",
       "      <td>2.242456</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.190714</td>\n",
       "      <td>0.582513</td>\n",
       "      <td>-0.510020</td>\n",
       "      <td>1.007777</td>\n",
       "      <td>0.407904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205883</td>\n",
       "      <td>-0.231246</td>\n",
       "      <td>-0.598498</td>\n",
       "      <td>-0.532398</td>\n",
       "      <td>0.332631</td>\n",
       "      <td>-0.144089</td>\n",
       "      <td>0.203178</td>\n",
       "      <td>0.709978</td>\n",
       "      <td>0.144264</td>\n",
       "      <td>0.346295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00427279d72064e7fb69</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942888</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.601196</td>\n",
       "      <td>1.467724</td>\n",
       "      <td>0.610288</td>\n",
       "      <td>1.937989</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017266</td>\n",
       "      <td>-0.192892</td>\n",
       "      <td>-0.581323</td>\n",
       "      <td>-0.603976</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>-0.217524</td>\n",
       "      <td>0.190385</td>\n",
       "      <td>0.566311</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>0.365409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00444b67aaabdf740a68</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326796</td>\n",
       "      <td>0.381992</td>\n",
       "      <td>0.167470</td>\n",
       "      <td>0.415445</td>\n",
       "      <td>-0.224419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010629</td>\n",
       "      <td>-0.248850</td>\n",
       "      <td>-0.683986</td>\n",
       "      <td>-0.542475</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.109113</td>\n",
       "      <td>0.173260</td>\n",
       "      <td>0.666322</td>\n",
       "      <td>0.347690</td>\n",
       "      <td>0.192940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 823 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               anime_id  type  episodes  source  duration   members  watching  \\\n",
       "0  000ba7f7e34e107e7544     5  2.242456       6         0 -0.190714  0.582513   \n",
       "1  00427279d72064e7fb69     5  0.942888       6         0  1.601196  1.467724   \n",
       "2  00444b67aaabdf740a68     5  0.051643       6         0  0.326796  0.381992   \n",
       "\n",
       "   completed   on_hold   dropped  ...  mBERT_758  mBERT_759  mBERT_760  \\\n",
       "0  -0.510020  1.007777  0.407904  ...  -0.205883  -0.231246  -0.598498   \n",
       "1   0.610288  1.937989  1.090300  ...  -0.017266  -0.192892  -0.581323   \n",
       "2   0.167470  0.415445 -0.224419  ...  -0.010629  -0.248850  -0.683986   \n",
       "\n",
       "   mBERT_761  mBERT_762  mBERT_763  mBERT_764  mBERT_765  mBERT_766  mBERT_767  \n",
       "0  -0.532398   0.332631  -0.144089   0.203178   0.709978   0.144264   0.346295  \n",
       "1  -0.603976   0.004401  -0.217524   0.190385   0.566311   0.227716   0.365409  \n",
       "2  -0.542475   0.118411   0.109113   0.173260   0.666322   0.347690   0.192940  \n",
       "\n",
       "[3 rows x 823 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime_preprocessd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応コサイン類似度を確認して、「近い作品」が「似ている」のか確かめてみたいと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "やはり俺の青春ラブコメはまちがっている。続 Slice of Life, Comedy, Drama, Romance, School TBS, Marvelous AQL, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "\n",
      "Most similar texts:\n",
      "やはり俺の青春ラブコメはまちがっている。完 Slice of Life, Comedy, Drama, Romance, School Marvelous, TBS, Movic, Delfi Sound, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "アウトブレイク・カンパニー Harem, Comedy, Parody, Fantasy Pony Canyon, TBS, Kodansha, Movic, DAX Production Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "パパのいうことを聞きなさい！ Comedy, Romance, Slice of Life Starchild Records, KlockWorx, PPP, Studio Mausu, Shueisha Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "マンガ家さんとアシスタントさんと THE ANIMATION Harem, Slice of Life, Comedy, Ecchi, Seinen Lantis, Magic Capsule, Showgate Sentai Filmworks 265 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている。 Slice of Life, Comedy, Drama, Romance, School Geneon Universal Entertainment, TBS, Delfi Sound, Marvelous AQL, Atelier Musa Sentai Filmworks 41 PG-13 - Teens 13 or older\n",
      "涼宮ハルヒの憂鬱 Comedy, Mystery, Parody, Romance, School, Sci-Fi, Slice of Life Kadokawa Shoten Funimation, Bandai Entertainment 113 PG-13 - Teens 13 or older\n",
      "いなり、こんこん、恋いろは。 Comedy, Romance, School, Seinen, Supernatural DAX Production, flying DOG Funimation 168 PG-13 - Teens 13 or older\n",
      "世話やきキツネの仙狐さん Slice of Life, Comedy, Supernatural, Romance Docomo Anime Store, Kadokawa Funimation 59 PG-13 - Teens 13 or older\n",
      "ひぐらしのなく頃に礼 Mystery, Comedy, Psychological, Supernatural, Thriller Geneon Universal Entertainment, Frontier Works, Sotsu, Movic Sentai Filmworks 206 PG-13 - Teens 13 or older\n",
      "逆転裁判 ～その「真実」、異議あり！～ Comedy, Drama, Mystery, Police Aniplex, Yomiuri Telecasting, Capcom, Trinity Sound Funimation, Crunchyroll 1 PG-13 - Teens 13 or older\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# サンプルの作品index\n",
    "sample_index = 18\n",
    "cosine_sim_scores = cosine_sim_matrix[sample_index]\n",
    "sorted_indices = np.argsort(cosine_sim_scores)[::-1]\n",
    "\n",
    "print(\"Sample text:\")\n",
    "print(anime_preprocess.df[\"combined_features\"].to_numpy()[sample_index])\n",
    "print(\"\\nMost similar texts:\")\n",
    "for i in sorted_indices[1:11]:\n",
    "    print(anime_preprocess.df[\"combined_features\"].to_numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「俺ガイル」がそのシリーズと近いところにいます。  \n",
    "でも他はどうなんだろうか。  \n",
    "微妙な気もしますね。モデルの限界かもしれません。  \n",
    "実はこの後、E5のモデルでも埋め込みを試しているので、そちらもコードと結果を載せておきます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, model_name='intfloat/multilingual-e5-small'):\n",
    "        self.texts = texts\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self, device=None, model_name='model/multilingual-e5-small'):\n",
    "        self.model_name = model_name\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "    def get_embeddings(self, texts, batch_size=16):\n",
    "        dataset = TextDataset(texts, self.model_name)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader):\n",
    "                inputs = {name: tensor.to(self.device) for name, tensor in batch.items()}\n",
    "                outputs = self.model(**inputs)\n",
    "                embeddings.append(self.average_pool(outputs.last_hidden_state, inputs['attention_mask']).cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "model/multilingual-e5-small is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m    602\u001b[0m         config_file,\n\u001b[0;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    604\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    605\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    606\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    607\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    608\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\utils\\hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    285\u001b[0m         url_or_filename,\n\u001b[0;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\utils\\hub.py:495\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    494\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mhead(url, headers\u001b[39m=\u001b[39mheaders, allow_redirects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39mproxies, timeout\u001b[39m=\u001b[39metag_timeout)\n\u001b[1;32m--> 495\u001b[0m _raise_for_status(r)\n\u001b[0;32m    496\u001b[0m etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m401 Client Error: Repository not found for url: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf the repo is private, make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    422\u001b[0m response\u001b[39m.\u001b[39mraise_for_status()\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/model/multilingual-e5-small/resolve/main/config.json. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\kaggle\\atmacup\\#15\\TabNet+mBERT.ipynb Cell 26\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# smallモデル\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embedder \u001b[39m=\u001b[39m TextEmbedder()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embeddings_small \u001b[39m=\u001b[39m embedder\u001b[39m.\u001b[39mget_embeddings(anime_preprocess\u001b[39m.\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mcombined_features\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[1;32md:\\Code\\kaggle\\atmacup\\#15\\TabNet+mBERT.ipynb Cell 26\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel/multilingual-e5-small\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m model_name\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device \u001b[39mif\u001b[39;00m device \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:423\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_auto\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 423\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    424\u001b[0m         pretrained_model_name_or_path, return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[0;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:705\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m    704\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 705\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    552\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    555\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\configuration_utils.py:613\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m    602\u001b[0m         config_file,\n\u001b[0;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m--> 613\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    614\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier listed on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a token having \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpermission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    617\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m \u001b[39mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[0;32m    620\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    621\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m is not a valid git identifier (branch name, tag name or commit id) that exists for this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    622\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel name. Check the model page at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mavailable revisions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    624\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: model/multilingual-e5-small is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "# smallモデル\n",
    "embedder = TextEmbedder()\n",
    "embeddings_small = embedder.get_embeddings(anime_preprocess.df['combined_features'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_small = np.load(\"train/mBERT_embedding_small.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "やはり俺の青春ラブコメはまちがっている。続 Slice of Life, Comedy, Drama, Romance, School TBS, Marvelous AQL, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "\n",
      "Most similar texts:\n",
      "やはり俺の青春ラブコメはまちがっている。完 Slice of Life, Comedy, Drama, Romance, School Marvelous, TBS, Movic, Delfi Sound, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている。 Slice of Life, Comedy, Drama, Romance, School Geneon Universal Entertainment, TBS, Delfi Sound, Marvelous AQL, Atelier Musa Sentai Filmworks 41 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている。OVA「こちらとしても彼ら彼女らの行く末に幸多からんことを願わざるを得ない。」 Comedy, Romance, School Unknown Unknown 41 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている. 続 きっと, 女の子はお砂糖とスパイスと素敵な何かでできている。 Comedy, Romance, School 5pb. feel. 266 PG-13 - Teens 13 or older\n",
      "僕らはみんな河合荘 Slice of Life, Comedy, Romance, School, Seinen TBS Sentai Filmworks 41 PG-13 - Teens 13 or older\n",
      "坂本ですが？ Slice of Life, Comedy, School, Seinen TBS, DAX Production, King Records Sentai Filmworks 206 PG-13 - Teens 13 or older\n",
      "坂本ですが？ Slice of Life, Comedy, School, Seinen Kadokawa Shoten, TBS, DAX Production, Daiichikosho, King Records, NichiNare Sentai Filmworks 206 PG-13 - Teens 13 or older\n",
      "未確認で進行形 Slice of Life, Comedy, Romance, School Sotsu, DAX Production, TOHO animation, RAY, Ichijinsha Sentai Filmworks 59 PG-13 - Teens 13 or older\n",
      "恋愛ラボ Comedy, Romance, School Aniplex, Dentsu, Mainichi Broadcasting System Sentai Filmworks 59 PG-13 - Teens 13 or older\n",
      "俺の脳内選択肢が、学園ラブコメを全力で邪魔している Harem, Comedy, Romance, School DAX Production, Studio Jack, MAGES. Sentai Filmworks 57 PG-13 - Teens 13 or older\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_matrix = cosine_similarity(embeddings_small)\n",
    "\n",
    "# サンプルの作品index\n",
    "sample_index = 18\n",
    "cosine_sim_scores = cosine_sim_matrix[sample_index]\n",
    "sorted_indices = np.argsort(cosine_sim_scores)[::-1]\n",
    "\n",
    "print(\"Sample text:\")\n",
    "print(anime_preprocess.df[\"combined_features\"].to_numpy()[sample_index])\n",
    "print(\"\\nMost similar texts:\")\n",
    "for i in sorted_indices[1:11]:\n",
    "    print(anime_preprocess.df[\"combined_features\"].to_numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42678e70e0e24017b3a41569eec014bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like intfloat/multilingual-e5-large is not the path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\modeling_utils.py:2007\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2005\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2006\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m-> 2007\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m   2008\u001b[0m         archive_file,\n\u001b[0;32m   2009\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   2010\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   2011\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   2012\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   2013\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   2014\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   2015\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   2016\u001b[0m     )\n\u001b[0;32m   2018\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\utils\\hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    285\u001b[0m         url_or_filename,\n\u001b[0;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\utils\\hub.py:554\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    555\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m                 )\n\u001b[0;32m    559\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\kaggle\\atmacup\\#15\\TabNet+mBERT.ipynb Cell 28\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# largeモデル\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embedder \u001b[39m=\u001b[39m TextEmbedder(model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mintfloat/multilingual-e5-large\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embeddings_large \u001b[39m=\u001b[39m embedder\u001b[39m.\u001b[39mget_embeddings(anime_preprocess\u001b[39m.\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mcombined_features\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[1;32md:\\Code\\kaggle\\atmacup\\#15\\TabNet+mBERT.ipynb Cell 28\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel/multilingual-e5-small\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m model_name\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device \u001b[39mif\u001b[39;00m device \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/atmacup/%2315/TabNet%2BmBERT.ipynb#X34sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    445\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    447\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m )\n",
      "File \u001b[1;32me:\\Envs\\kaggle1\\lib\\site-packages\\transformers\\modeling_utils.py:2088\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2083\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2084\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2085\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2087\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m-> 2088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2089\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2090\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2091\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m directory containing a file named \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2092\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the library in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2093\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m offline mode at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2094\u001b[0m     )\n\u001b[0;32m   2095\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[0;32m   2096\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2097\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load the model for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2098\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2102\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like intfloat/multilingual-e5-large is not the path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "# largeモデル\n",
    "embedder = TextEmbedder(model_name='intfloat/multilingual-e5-large')\n",
    "embeddings_large = embedder.get_embeddings(anime_preprocess.df['combined_features'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_large = np.load(\"train/mBERT_embedding_large.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "やはり俺の青春ラブコメはまちがっている。続 Slice of Life, Comedy, Drama, Romance, School TBS, Marvelous AQL, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "\n",
      "Most similar texts:\n",
      "やはり俺の青春ラブコメはまちがっている。完 Slice of Life, Comedy, Drama, Romance, School Marvelous, TBS, Movic, Delfi Sound, NBCUniversal Entertainment Japan Sentai Filmworks 266 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている。 Slice of Life, Comedy, Drama, Romance, School Geneon Universal Entertainment, TBS, Delfi Sound, Marvelous AQL, Atelier Musa Sentai Filmworks 41 PG-13 - Teens 13 or older\n",
      "やはり俺の青春ラブコメはまちがっている. 続 きっと, 女の子はお砂糖とスパイスと素敵な何かでできている。 Comedy, Romance, School 5pb. feel. 266 PG-13 - Teens 13 or older\n",
      "アマガミSS+ plus Slice of Life, Comedy, Romance, School TBS Sentai Filmworks 9 PG-13 - Teens 13 or older\n",
      "きんいろモザイク Slice of Life, Comedy, School, Seinen Media Factory, Showgate Sentai Filmworks 210 PG-13 - Teens 13 or older\n",
      "カラフル Drama, Slice of Life, Supernatural Aniplex, Sony Music Entertainment, Imagine Sentai Filmworks 225 PG-13 - Teens 13 or older\n",
      "ハナヤマタ Slice of Life, Comedy, School TV Tokyo, Avex Entertainment, Sotsu, Movic, AT-X, DIVE II Entertainment, Bandai Namco Games Sentai Filmworks 126 PG-13 - Teens 13 or older\n",
      "ココロコネクト Slice of Life, Comedy, Supernatural, Drama, Romance, School Starchild Records, Enterbrain Sentai Filmworks 176 PG-13 - Teens 13 or older\n",
      "マンガ家さんとアシスタントさんと THE ANIMATION Harem, Slice of Life, Comedy, Ecchi, Seinen Lantis, Magic Capsule, Showgate Sentai Filmworks 265 PG-13 - Teens 13 or older\n",
      "ピーチガール Slice of Life, Drama, Romance, School, Shoujo TV Tokyo, Marvelous, Studio Jack Funimation 205 PG-13 - Teens 13 or older\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_matrix = cosine_similarity(embeddings_large)\n",
    "\n",
    "# サンプルの作品index\n",
    "sample_index = 18\n",
    "cosine_sim_scores = cosine_sim_matrix[sample_index]\n",
    "sorted_indices = np.argsort(cosine_sim_scores)[::-1]\n",
    "\n",
    "print(\"Sample text:\")\n",
    "print(anime_preprocess.df[\"combined_features\"].to_numpy()[sample_index])\n",
    "print(\"\\nMost similar texts:\")\n",
    "for i in sorted_indices[1:11]:\n",
    "    print(anime_preprocess.df[\"combined_features\"].to_numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全然様相が違うことがわかります。  \n",
    "E5モデルのほうが、シリーズものが近しいところにいるので、より「らしい」特徴量なのかもしれません。  \n",
    "「俺ガイル」でしかそのあたりは確認していないので、「俺ガイルベンチマーク」がどれだけ信憑性のあるものなのかは未知数です。  \n",
    "余談ですが、僕はいろはすが好きです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.csvの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainPreprocess(object):\n",
    "    def __init__(self, train, test, mode=\"train\"):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "        self.df_all = pd.concat([train, test]).reset_index(drop=True)\n",
    "        self.preprocessing_methods = [\n",
    "            \"user_id\"\n",
    "        ]\n",
    "\n",
    "    def preprocess_all(self):\n",
    "        # すべての処理を実行する\n",
    "        for method_name in self.preprocessing_methods:\n",
    "            getattr(self, method_name)()\n",
    "\n",
    "    def user_id(self):\n",
    "        # user_idのencoding\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder.fit(self.df_all[\"user_id\"])\n",
    "        self.train[\"user_id\"] = self.encoder.transform(self.train[\"user_id\"])\n",
    "        self.test[\"user_id\"] = self.encoder.transform(self.test[\"user_id\"])\n",
    "\n",
    "def merge_anime(df, anime):\n",
    "    \"\"\"trainまたはtestとanimeをmergeする\n",
    "    \"\"\"\n",
    "    df_merge = pd.merge(df, anime, on=[\"anime_id\"], how=\"left\")\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_train_test(train, test):\n",
    "    train[\"train_test\"] = \"train\"\n",
    "    test[\"train_test\"] = \"test\"\n",
    "    df_all = pd.concat([train, test])\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocess = TrainPreprocess(train=train, test=test)\n",
    "train_preprocess.preprocess_all()\n",
    "df_merge_train = merge_anime(train_preprocess.train, df_anime_preprocessd)\n",
    "df_merge_test = merge_anime(train_preprocess.test, df_anime_preprocessd)\n",
    "df_merge_all = concat_train_test(df_merge_train, df_merge_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018\n",
       "1    2018\n",
       "2    2006\n",
       "3    2016\n",
       "4    2003\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_all.head()['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここはuser_idをラベルエンコーディングしてくっつけるだけです。  \n",
    "このあとTabNetのPretrainを行なうためにtest データを繋げているんですが、こちらは本来未知なものではあるので、concatするかどうかは思想によるかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabNetによる学習\n",
    "\n",
    "ここからはTabNetによる学習を行っていきます。  \n",
    "\n",
    "TabNetには、「カテゴリカル変数のembedding」という機能があるので、`user_id`, `type`, `source` の3つについて、埋め込みベクトルを作らせてみます。  \n",
    "各次元数は結構feelingです。気になる方は色々試してみてください。  \n",
    "なお、ここからの注意点として、Google Colab環境の場合、最初からinstallされているpytorchが邪魔をするので、以下でTabNetのライブラリを入れてください。  \n",
    "\n",
    "```shell\n",
    "pip uninstall torchdata  torchtext torchvision torchaudio\n",
    "pip install pytorch-tabnet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class TabNetBaseline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tabnet_params,\n",
    "        embedding_cols,\n",
    "        embedding_idx,\n",
    "        cat_dims,\n",
    "        embedding_dims,\n",
    "        splitter=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        seed=777\n",
    "        ):\n",
    "        self.tabnet_params = tabnet_params\n",
    "        self.embedding_cols = embedding_cols\n",
    "        self.embedding_idx = embedding_idx\n",
    "        self.cat_dims = cat_dims\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.splitter = splitter\n",
    "        self.seed = seed\n",
    "        self.models = []\n",
    "        self.oof_preds = None\n",
    "        self.pretrained_model = None\n",
    "\n",
    "    def prepare_pretrain_data(self, df_pretrain):\n",
    "\n",
    "        for embc, d in zip(self.embedding_cols, self.cat_dims):\n",
    "            df_pretrain[embc] = df_pretrain[embc].replace({-1: df_pretrain[embc].max() + 1})\n",
    "            assert (df_pretrain[embc].max()+1 == d)\n",
    "            assert (len(df_pretrain[embc].unique()) == d)\n",
    "            assert df_pretrain[embc].min()==0\n",
    "\n",
    "        return df_pretrain\n",
    "\n",
    "    def pretrain(self, df_pretrain):\n",
    "        if not self.pretrained_model:\n",
    "            df_pretrain = self.prepare_pretrain_data(df_pretrain)\n",
    "            train_unsp, val_unsup = train_test_split(df_pretrain,  test_size=0.3, random_state=self.seed)\n",
    "\n",
    "            unsupervised_model = TabNetPretrainer(\n",
    "                optimizer_fn=torch.optim.Adam,\n",
    "                optimizer_params=dict(lr=0.1),\n",
    "                scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "                cat_idxs=self.embedding_idx, \n",
    "                cat_dims=self.cat_dims,\n",
    "                cat_emb_dim=self.embedding_dims,\n",
    "                **self.tabnet_params\n",
    "            )\n",
    "\n",
    "            unsupervised_model.fit(\n",
    "                X_train=train_unsp.values,\n",
    "                eval_set=[val_unsup.values],\n",
    "                pretraining_ratio=0.8,\n",
    "                max_epochs=300\n",
    "            )\n",
    "\n",
    "            self.pretrained_model = unsupervised_model\n",
    "        return self.pretrained_model\n",
    "\n",
    "    def train(self, X, y, groups=None):\n",
    "        self.models = []\n",
    "        self.oof_preds = np.zeros(len(X))\n",
    "        scores = []\n",
    "        for train_index, valid_index in self.splitter.split(X, y, groups=groups):\n",
    "            unsupervised_model = self.pretrained_model\n",
    "\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "            reg = TabNetRegressor(\n",
    "                optimizer_fn=torch.optim.Adam,\n",
    "                optimizer_params=dict(lr=0.03),\n",
    "                scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                cat_idxs=self.embedding_idx, \n",
    "                cat_dims=self.cat_dims,\n",
    "                cat_emb_dim=self.embedding_dims,\n",
    "                **self.tabnet_params\n",
    "            )\n",
    "\n",
    "            reg.fit(\n",
    "                X_train=X_train.values, y_train=y_train.values.reshape(-1, 1),\n",
    "                eval_set=[(X_train.values, y_train.values.reshape(-1, 1)), (X_valid.values, y_valid.values.reshape(-1, 1))],\n",
    "                eval_name=['train', 'valid'],\n",
    "                eval_metric=['rmse'],\n",
    "                batch_size=2048, virtual_batch_size=2048,\n",
    "                drop_last=True,\n",
    "                from_unsupervised=unsupervised_model,\n",
    "                max_epochs=1000,\n",
    "                patience=12,\n",
    "                num_workers=4,\n",
    "            )\n",
    "            self.models.append(reg)\n",
    "\n",
    "            y_pred = reg.predict(X_valid.values)[:, 0]\n",
    "            self.oof_preds[valid_index] = y_pred\n",
    "            score = mean_squared_error(y_valid, y_pred, squared=False)  # RMSE score\n",
    "            scores.append(score)\n",
    "        self.cv_score = np.mean(scores)\n",
    "\n",
    "    def inference(self, X):\n",
    "        y_preds = []\n",
    "        for model in self.models:\n",
    "            y_pred = model.predict(X)[:, 0]\n",
    "            y_preds.append(y_pred)\n",
    "        y_preds = np.mean(y_preds, axis=0)\n",
    "        return y_preds\n",
    "\n",
    "    def plot_feature_importance(self):\n",
    "        df_features_list = []\n",
    "        for model in self.models:\n",
    "            df = pd.DataFrame(data ={\n",
    "                \"feature_importance\" : model.feature_importances_,\n",
    "                \"feature_names\" : self.features\n",
    "            })\n",
    "            df_features_list.append(df)\n",
    "\n",
    "        df_features = pd.concat(df_features_list).sort_values(by='feature_importance', ascending=False)\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(5, 10))\n",
    "        sns.barplot(\n",
    "            data = df_features,\n",
    "            x = 'feature_importance',\n",
    "            y = 'feature_names',\n",
    "            capsize=0.1, errwidth=1.2,\n",
    "            ax = ax\n",
    "        )\n",
    "        return f, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この辺のハイパーパラメータは調整すると色々結果が変わるので面白いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrainerのハイパーパラメータ\n",
    "tabnet_params = {\n",
    "    'mask_type' : 'entmax',\n",
    "    'n_d' : 64,\n",
    "    'n_a': 64,\n",
    "    'n_steps': 3,\n",
    "    'gamma': 0.9,\n",
    "    'verbose': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrainをしていきます。  \n",
    "事前学習はしたほうがよいとTabNetでは言われているのでするお気持ちです。  \n",
    "たぶん精度が変わると思います、たぶん。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"anime_id\", \"score\", \"train_test\"]\n",
    "df_pretrain = df_merge_all.drop(columns=drop_cols) # 目的変数は使わないので落とす\n",
    "\n",
    "# embeddingするカラム\n",
    "embeding_cols = ['user_id', 'type', 'source']\n",
    "# 各々のユニーク数\n",
    "col_uniques = [ len(df_pretrain[c].unique()) for c in  embeding_cols ]\n",
    "# カラムの番号\n",
    "embeding_idx = [ i for i, c in  enumerate(df_pretrain.columns) if c in embeding_cols]\n",
    "cat_dims = [ v for k, v in zip(embeding_cols, col_uniques) if k in embeding_cols]\n",
    "# 埋め込み次元\n",
    "embeding_dims = [ i // 2 if i<100 else 64 for i in cat_dims ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1998, 6, 13]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Envs\\kaggle1\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 106.19549| val_0_unsup_loss_numpy: 102.87663269042969|  0:00:32s\n",
      "epoch 10 | loss: 5.39076 | val_0_unsup_loss_numpy: 52.667579650878906|  0:03:57s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_unsup_loss_numpy = 36.580501556396484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Envs\\kaggle1\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabNetPretrainer(n_d=64, n_a=64, n_steps=3, gamma=0.9, cat_idxs=[0, 1, 3], cat_dims=[1998, 6, 13], cat_emb_dim=[64, 3, 6], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=10, optimizer_fn=&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;, optimizer_params={&#x27;lr&#x27;: 0.1}, scheduler_fn=None, scheduler_params={&#x27;step_size&#x27;: 10, &#x27;gamma&#x27;: 0.9}, mask_type=&#x27;entmax&#x27;, input_dim=823, output_dim=None, device_name=&#x27;auto&#x27;, n_shared_decoder=1, n_indep_decoder=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TabNetPretrainer</label><div class=\"sk-toggleable__content\"><pre>TabNetPretrainer(n_d=64, n_a=64, n_steps=3, gamma=0.9, cat_idxs=[0, 1, 3], cat_dims=[1998, 6, 13], cat_emb_dim=[64, 3, 6], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=10, optimizer_fn=&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;, optimizer_params={&#x27;lr&#x27;: 0.1}, scheduler_fn=None, scheduler_params={&#x27;step_size&#x27;: 10, &#x27;gamma&#x27;: 0.9}, mask_type=&#x27;entmax&#x27;, input_dim=823, output_dim=None, device_name=&#x27;auto&#x27;, n_shared_decoder=1, n_indep_decoder=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TabNetPretrainer(n_d=64, n_a=64, n_steps=3, gamma=0.9, cat_idxs=[0, 1, 3], cat_dims=[1998, 6, 13], cat_emb_dim=[64, 3, 6], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=10, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.1}, scheduler_fn=None, scheduler_params={'step_size': 10, 'gamma': 0.9}, mask_type='entmax', input_dim=823, output_dim=None, device_name='auto', n_shared_decoder=1, n_indep_decoder=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnet_mbert = TabNetBaseline(\n",
    "    tabnet_params=tabnet_params,\n",
    "    embedding_cols=embeding_cols,\n",
    "    embedding_idx=embeding_idx,\n",
    "    cat_dims=cat_dims,\n",
    "    embedding_dims=embeding_dims\n",
    ")\n",
    "tabnet_mbert.pretrain(df_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境を切り替えて実行した結果をまとめるのが面倒だったので、学習時の出力をペタリ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "epoch 0  | loss: 4.61219 | val_0_unsup_loss_numpy: 0.8416699767112732|  0:00:21s\n",
    "epoch 10 | loss: 0.65599 | val_0_unsup_loss_numpy: 0.5929800271987915|  0:03:44s\n",
    "\n",
    "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_unsup_loss_numpy = 0.44297999143600464\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
    "  warnings.warn(wrn_msg)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrain時にこのくらいまで収束してくれていると、性能が発揮しやすい印象です。  \n",
    "保存すると、`.zip`形式になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "tabnet_mbert.pretrained_model.save_model('../model/pretrain_mBERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に予測モデルを学習させていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_merge_all.loc[df_merge_all[\"train_test\"]==\"train\"].copy().drop(columns=drop_cols)\n",
    "train_y = df_merge_all.loc[df_merge_all[\"train_test\"]==\"train\"].copy()['score']\n",
    "\n",
    "loaded_pretrain = TabNetPretrainer()\n",
    "loaded_pretrain.load_model('../model/pretrain_mBERT.zip')\n",
    "tabnet_mbert.pretrained_model = loaded_pretrain\n",
    "tabnet_mbert.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力はこんな感じです。  \n",
    "```\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
    "  warnings.warn(f\"Device used : {self.device}\")\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:231: UserWarning: Loading weights from unsupervised pretraining\n",
    "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
    "epoch 0  | loss: 8.73306 | train_rmse: 1.59975 | valid_rmse: 1.61224 |  0:00:11s\n",
    "epoch 10 | loss: 1.21449 | train_rmse: 1.04232 | valid_rmse: 1.20917 |  0:02:04s\n",
    "epoch 20 | loss: 0.76145 | train_rmse: 0.77771 | valid_rmse: 1.25488 |  0:03:57s\n",
    "\n",
    "Early stopping occurred at epoch 24 with best_epoch = 12 and best_valid_rmse = 1.19892\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
    "  warnings.warn(wrn_msg)\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
    "  warnings.warn(f\"Device used : {self.device}\")\n",
    "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:231: UserWarning: Loading weights from unsupervised pretraining\n",
    "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
    "epoch 0  | loss: 7.54927 | train_rmse: 1.57612 | valid_rmse: 1.57344 |  0:00:11s\n",
    "epoch 10 | loss: 1.53426 | train_rmse: 1.22548 | valid_rmse: 1.25262 |  0:02:03s\n",
    "epoch 20 | loss: 1.03442 | train_rmse: 0.95992 | valid_rmse: 1.21042 |  0:03:55s\n",
    "\n",
    "Early stopping occurred at epoch 26 with best_epoch = 14 and best_valid_rmse = 1.18938\n",
    "```\n",
    "\n",
    "Foldごとのスコア  \n",
    "| Fold | validation rmse | \n",
    "| ---- | --------------- | \n",
    "| 0    | 1.19892         | \n",
    "| 1    | 1.18938         | \n",
    "| 2    | 1.19768         | \n",
    "| 3    | 1.19511         | \n",
    "| 4    | 1.19257         | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df_merge_all.loc[df_merge_all[\"train_test\"]==\"test\"].copy().drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tabnet_mbert.inference(test_x.to_numpy())\n",
    "sample_submission[\"score\"] = pred\n",
    "sample_submission.to_csv(\"../submission/06_tabnet_random.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル保存\n",
    "for i, regression_model in enumerate(tabnet_mbert.models):\n",
    "    regression_model.save_model(f'../model/06_tabnet_random_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上です。  \n",
    "これ書いてたらもう73位まで落ちてました！！  \n",
    "ここからスコア巻き返せるかな。俺たちの戦いはこれからだ！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
